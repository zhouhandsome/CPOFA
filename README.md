# 智能算法综合实践大作业



....图像分类是计算机视觉中的基本任务，涉及将图像分配到预定义的类别。早期的方法依赖于手工设计的特征提取技术和传统机器学习算法，如支持向量机（SVM）、k近邻（k-NN）和朴素贝叶斯。20世纪80年代，神经网络如多层感知器（MLP）和卷积神经网络（CNN）开始应用于图像分类。

2012年，AlexNet在ImageNet竞赛中取得突破，标志着深度学习在图像分类中的广泛应用。2014年，由Simonyan和Zisserman提出的VGG模型通过堆叠较小的卷积核（3x3）构建深度网络，取得了优异的分类效果，推动了模型向更大更深的方向发展。然而，当神经网络的深度增加时，会出现退化现象。为了解决这个问题，2015年，He等人提出的ResNet模型通过残差连接解决了深层网络的梯度消失问题，使得更深的网络可以被有效训练。

随着Transformer在自然语言处理领域取得广泛成功，研究者们开始尝试将其应用于计算机视觉领域，但大部分工作只是替换传统卷积神经网络的一部分。直到2020年，Google Research团队提出了Vision Transformer (ViT)，首次将标准的Transformer架构应用于纯粹的图像分类任务，对整个图像分类流程进行了最少的修改。ViT展示了在图像分类任务中的巨大潜力，进一步拓展了Transformer在计算机视觉中的应用。

本试验，旨在设计一个具有高度可扩展性，便于修改的图像分类系统，并在此系统上，复现上述的经典算法（AlexNet，VGG，ResNet，Vision Transforme）
并比较算法之间的区别和优缺点。